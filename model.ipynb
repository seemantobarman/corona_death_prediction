{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Data Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Importing the dataset__\n",
    "original_data = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__inserting random values in age__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"age\"]):\n",
    "        original_data.loc[_i, \"age\"] = random.randint(20,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#__Spliting and removing replacing words__\n",
    "column_to_add = []\n",
    "for _symptom in original_data.loc[:,\"symptoms\"]:\n",
    "   if type(_symptom) == str:\n",
    "      _temp = _symptom.replace(\"feve\",\"fever\").replace(\"feaver\",\"fever\").replace(\"coughing\",\"cough\").replace(\"feverr\",\"fever\").replace(\"difficult in breathing\",\"difficulty breathing\")\n",
    "      column_to_add.extend(_temp.split(\",\"))\n",
    "#__individual symptoms__ \n",
    "new_column = []\n",
    "for _column in column_to_add:\n",
    "   _temp_clm = _column.strip()\n",
    "   new_column.append(_temp_clm)\n",
    "\n",
    "#__removing duplicates__\n",
    "new_column = list(dict.fromkeys(new_column))\n",
    "new_column = new_column[:20]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__adding the columns of symptoms in the main file__\n",
    "for _column in new_column:\n",
    "    original_data[_column] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Adding random items from the new_column in the Symptoms__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"symptoms\"]):\n",
    "        _random_int = random.randint(1,10)\n",
    "        original_data.at[_i, \"symptoms\"] = random.sample(new_column,k=_random_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the missing genders randomly__\n",
    "_gender = [\"male\",\"female\"]\n",
    "\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"gender\"]):\n",
    "        original_data.at[_i, \"gender\"] = random.choice(_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the missing death numbers randomly__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"death\"]):\n",
    "        original_data.at[_i, \"death\"] = random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Filling all the symptoms cells__\n",
    "original_data.iloc[:,5:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#__Selecting 1 if symptoms are detected__\n",
    "for _i in range(len(original_data)):\n",
    "    for _each in original_data.loc[_i, \"symptoms\"]:\n",
    "        original_data.at[_i,_each] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Final processed dataset__\n",
    "processed_data = original_data.drop(labels=\"symptoms\", axis=1).iloc[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Independent variable__\n",
    "X = processed_data.iloc[:,2:24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Dependent Variable (Death)__\n",
    "Y = processed_data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Encodeing the gender__\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "_labelEncoder_X_Gender = LabelEncoder()\n",
    "X[:,0] = _labelEncoder_X_Gender.fit_transform(X[:,0])\n",
    "\n",
    "_onehotencoder = OneHotEncoder(categorical_features= [0])\n",
    "X = _onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Avoiding dummy variable trap__\n",
    "\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Spliting the dataset into training set and test set__\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Feature Scaling__\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_parameters = sc.fit(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = sc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "#__Making the ANN__\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__initializing the ANN__\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the input layer and the first hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu', input_dim=22))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the second hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the second hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the output layer__\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "#__Compiling the ANN__\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n2400/2400 [==============================] - 0s - loss: 0.5562 - acc: 0.7038\nEpoch 283/500\n2400/2400 [==============================] - 0s - loss: 0.5689 - acc: 0.6954\nEpoch 284/500\n2400/2400 [==============================] - 0s - loss: 0.5662 - acc: 0.6979\nEpoch 285/500\n2400/2400 [==============================] - 0s - loss: 0.5747 - acc: 0.6921\nEpoch 286/500\n2400/2400 [==============================] - 0s - loss: 0.5634 - acc: 0.6983\nEpoch 287/500\n2400/2400 [==============================] - 0s - loss: 0.5732 - acc: 0.6879\nEpoch 288/500\n2400/2400 [==============================] - 0s - loss: 0.5597 - acc: 0.7067\nEpoch 289/500\n2400/2400 [==============================] - 0s - loss: 0.5619 - acc: 0.7021\nEpoch 290/500\n2400/2400 [==============================] - 0s - loss: 0.5717 - acc: 0.6929\nEpoch 291/500\n2400/2400 [==============================] - 0s - loss: 0.5647 - acc: 0.7042\nEpoch 292/500\n2400/2400 [==============================] - 0s - loss: 0.5607 - acc: 0.6946\nEpoch 293/500\n2400/2400 [==============================] - 0s - loss: 0.5628 - acc: 0.6946\nEpoch 294/500\n2400/2400 [==============================] - 0s - loss: 0.5723 - acc: 0.6858\nEpoch 295/500\n2400/2400 [==============================] - 0s - loss: 0.5668 - acc: 0.6950\nEpoch 296/500\n2400/2400 [==============================] - 0s - loss: 0.5638 - acc: 0.6888\nEpoch 297/500\n2400/2400 [==============================] - 0s - loss: 0.5671 - acc: 0.6967\nEpoch 298/500\n2400/2400 [==============================] - 0s - loss: 0.5648 - acc: 0.6904\nEpoch 299/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6971\nEpoch 300/500\n2400/2400 [==============================] - 0s - loss: 0.5710 - acc: 0.7008\nEpoch 301/500\n2400/2400 [==============================] - 0s - loss: 0.5679 - acc: 0.7038\nEpoch 302/500\n2400/2400 [==============================] - 0s - loss: 0.5681 - acc: 0.6879\nEpoch 303/500\n2400/2400 [==============================] - 0s - loss: 0.5653 - acc: 0.7008\nEpoch 304/500\n2400/2400 [==============================] - 0s - loss: 0.5754 - acc: 0.6829\nEpoch 305/500\n2400/2400 [==============================] - 0s - loss: 0.5664 - acc: 0.6992\nEpoch 306/500\n2400/2400 [==============================] - 0s - loss: 0.5699 - acc: 0.6888\nEpoch 307/500\n2400/2400 [==============================] - 0s - loss: 0.5698 - acc: 0.6925\nEpoch 308/500\n2400/2400 [==============================] - 0s - loss: 0.5643 - acc: 0.6979\nEpoch 309/500\n2400/2400 [==============================] - 0s - loss: 0.5661 - acc: 0.6917\nEpoch 310/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.7000\nEpoch 311/500\n2400/2400 [==============================] - 0s - loss: 0.5667 - acc: 0.7008\nEpoch 312/500\n2400/2400 [==============================] - 0s - loss: 0.5612 - acc: 0.7013\nEpoch 313/500\n2400/2400 [==============================] - 0s - loss: 0.5665 - acc: 0.6942\nEpoch 314/500\n2400/2400 [==============================] - 0s - loss: 0.5576 - acc: 0.7054\nEpoch 315/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6842\nEpoch 316/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.7075\nEpoch 317/500\n2400/2400 [==============================] - 0s - loss: 0.5697 - acc: 0.6925\nEpoch 318/500\n2400/2400 [==============================] - 0s - loss: 0.5690 - acc: 0.6963\nEpoch 319/500\n2400/2400 [==============================] - 0s - loss: 0.5647 - acc: 0.6996\nEpoch 320/500\n2400/2400 [==============================] - 0s - loss: 0.5663 - acc: 0.6929\nEpoch 321/500\n2400/2400 [==============================] - 0s - loss: 0.5757 - acc: 0.6800\nEpoch 322/500\n2400/2400 [==============================] - 0s - loss: 0.5689 - acc: 0.7038\nEpoch 323/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.6963\nEpoch 324/500\n2400/2400 [==============================] - 0s - loss: 0.5696 - acc: 0.6875\nEpoch 325/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.6983\nEpoch 326/500\n2400/2400 [==============================] - 0s - loss: 0.5632 - acc: 0.6979\nEpoch 327/500\n2400/2400 [==============================] - 0s - loss: 0.5638 - acc: 0.6958\nEpoch 328/500\n2400/2400 [==============================] - 0s - loss: 0.5688 - acc: 0.6896\nEpoch 329/500\n2400/2400 [==============================] - 0s - loss: 0.5676 - acc: 0.6954\nEpoch 330/500\n2400/2400 [==============================] - 0s - loss: 0.5687 - acc: 0.6888\nEpoch 331/500\n2400/2400 [==============================] - 0s - loss: 0.5631 - acc: 0.7042\nEpoch 332/500\n2400/2400 [==============================] - 0s - loss: 0.5711 - acc: 0.6938\nEpoch 333/500\n2400/2400 [==============================] - 0s - loss: 0.5685 - acc: 0.7013\nEpoch 334/500\n2400/2400 [==============================] - 0s - loss: 0.5685 - acc: 0.6996\nEpoch 335/500\n2400/2400 [==============================] - 0s - loss: 0.5635 - acc: 0.7029\nEpoch 336/500\n2400/2400 [==============================] - 0s - loss: 0.5599 - acc: 0.6987\nEpoch 337/500\n2400/2400 [==============================] - 0s - loss: 0.5657 - acc: 0.6963\nEpoch 338/500\n2400/2400 [==============================] - 0s - loss: 0.5731 - acc: 0.6913\nEpoch 339/500\n2400/2400 [==============================] - 0s - loss: 0.5629 - acc: 0.7000\nEpoch 340/500\n2400/2400 [==============================] - 0s - loss: 0.5647 - acc: 0.6967\nEpoch 341/500\n2400/2400 [==============================] - 0s - loss: 0.5635 - acc: 0.6992\nEpoch 342/500\n2400/2400 [==============================] - 0s - loss: 0.5644 - acc: 0.6975\nEpoch 343/500\n2400/2400 [==============================] - 0s - loss: 0.5679 - acc: 0.6908\nEpoch 344/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.6925\nEpoch 345/500\n2400/2400 [==============================] - 0s - loss: 0.5708 - acc: 0.6850\nEpoch 346/500\n2400/2400 [==============================] - 0s - loss: 0.5695 - acc: 0.6875\nEpoch 347/500\n2400/2400 [==============================] - 0s - loss: 0.5571 - acc: 0.7083\nEpoch 348/500\n2400/2400 [==============================] - 0s - loss: 0.5685 - acc: 0.6983\nEpoch 349/500\n2400/2400 [==============================] - 0s - loss: 0.5599 - acc: 0.6988\nEpoch 350/500\n2400/2400 [==============================] - 0s - loss: 0.5692 - acc: 0.6942\nEpoch 351/500\n2400/2400 [==============================] - 0s - loss: 0.5639 - acc: 0.6983\nEpoch 352/500\n2400/2400 [==============================] - 0s - loss: 0.5600 - acc: 0.6971\nEpoch 353/500\n2400/2400 [==============================] - 0s - loss: 0.5713 - acc: 0.6946\nEpoch 354/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.7042\nEpoch 355/500\n2400/2400 [==============================] - 0s - loss: 0.5641 - acc: 0.7067\nEpoch 356/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6967\nEpoch 357/500\n2400/2400 [==============================] - 0s - loss: 0.5718 - acc: 0.6858\nEpoch 358/500\n2400/2400 [==============================] - 0s - loss: 0.5616 - acc: 0.6933\nEpoch 359/500\n2400/2400 [==============================] - 0s - loss: 0.5706 - acc: 0.6867\nEpoch 360/500\n2400/2400 [==============================] - 0s - loss: 0.5631 - acc: 0.7000\nEpoch 361/500\n2400/2400 [==============================] - 0s - loss: 0.5703 - acc: 0.6921\nEpoch 362/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6992\nEpoch 363/500\n2400/2400 [==============================] - 0s - loss: 0.5668 - acc: 0.7038\nEpoch 364/500\n2400/2400 [==============================] - 0s - loss: 0.5664 - acc: 0.7046\nEpoch 365/500\n2400/2400 [==============================] - 0s - loss: 0.5648 - acc: 0.7017\nEpoch 366/500\n2400/2400 [==============================] - 0s - loss: 0.5677 - acc: 0.6938\nEpoch 367/500\n2400/2400 [==============================] - 0s - loss: 0.5647 - acc: 0.6971\nEpoch 368/500\n2400/2400 [==============================] - 0s - loss: 0.5697 - acc: 0.6921\nEpoch 369/500\n2400/2400 [==============================] - 0s - loss: 0.5694 - acc: 0.6946\nEpoch 370/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.6992\nEpoch 371/500\n2400/2400 [==============================] - 0s - loss: 0.5549 - acc: 0.7054\nEpoch 372/500\n2400/2400 [==============================] - 0s - loss: 0.5705 - acc: 0.6933\nEpoch 373/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.7025\nEpoch 374/500\n2400/2400 [==============================] - 0s - loss: 0.5662 - acc: 0.6946\nEpoch 375/500\n2400/2400 [==============================] - 0s - loss: 0.5651 - acc: 0.6988\nEpoch 376/500\n2400/2400 [==============================] - 0s - loss: 0.5664 - acc: 0.7021\nEpoch 377/500\n2400/2400 [==============================] - 0s - loss: 0.5633 - acc: 0.6971\nEpoch 378/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6933\nEpoch 379/500\n2400/2400 [==============================] - 0s - loss: 0.5629 - acc: 0.6992\nEpoch 380/500\n2400/2400 [==============================] - 0s - loss: 0.5621 - acc: 0.7013\nEpoch 381/500\n2400/2400 [==============================] - 0s - loss: 0.5664 - acc: 0.6913\nEpoch 382/500\n2400/2400 [==============================] - 0s - loss: 0.5638 - acc: 0.7017\nEpoch 383/500\n2400/2400 [==============================] - 0s - loss: 0.5693 - acc: 0.6925\nEpoch 384/500\n2400/2400 [==============================] - 0s - loss: 0.5649 - acc: 0.6913\nEpoch 385/500\n2400/2400 [==============================] - 0s - loss: 0.5680 - acc: 0.6992\nEpoch 386/500\n2400/2400 [==============================] - 0s - loss: 0.5638 - acc: 0.7029\nEpoch 387/500\n2400/2400 [==============================] - 0s - loss: 0.5667 - acc: 0.6983\nEpoch 388/500\n2400/2400 [==============================] - 0s - loss: 0.5655 - acc: 0.7025\nEpoch 389/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6946\nEpoch 390/500\n2400/2400 [==============================] - 0s - loss: 0.5684 - acc: 0.6883\nEpoch 391/500\n2400/2400 [==============================] - 0s - loss: 0.5711 - acc: 0.6917\nEpoch 392/500\n2400/2400 [==============================] - 0s - loss: 0.5697 - acc: 0.7013\nEpoch 393/500\n2400/2400 [==============================] - 0s - loss: 0.5669 - acc: 0.6946\nEpoch 394/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6942\nEpoch 395/500\n2400/2400 [==============================] - 0s - loss: 0.5611 - acc: 0.6967\nEpoch 396/500\n2400/2400 [==============================] - 0s - loss: 0.5632 - acc: 0.6983\nEpoch 397/500\n2400/2400 [==============================] - 0s - loss: 0.5597 - acc: 0.7100\nEpoch 398/500\n2400/2400 [==============================] - 0s - loss: 0.5634 - acc: 0.7067\nEpoch 399/500\n2400/2400 [==============================] - 0s - loss: 0.5739 - acc: 0.6888\nEpoch 400/500\n2400/2400 [==============================] - 0s - loss: 0.5683 - acc: 0.6992\nEpoch 401/500\n2400/2400 [==============================] - 0s - loss: 0.5644 - acc: 0.6971\nEpoch 402/500\n2400/2400 [==============================] - 0s - loss: 0.5646 - acc: 0.7063\nEpoch 403/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.6913\nEpoch 404/500\n2400/2400 [==============================] - 0s - loss: 0.5718 - acc: 0.6958\nEpoch 405/500\n2400/2400 [==============================] - 0s - loss: 0.5542 - acc: 0.7075\nEpoch 406/500\n2400/2400 [==============================] - 0s - loss: 0.5632 - acc: 0.6963\nEpoch 407/500\n2400/2400 [==============================] - 0s - loss: 0.5661 - acc: 0.6917\nEpoch 408/500\n2400/2400 [==============================] - 0s - loss: 0.5605 - acc: 0.6996\nEpoch 409/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6975\nEpoch 410/500\n2400/2400 [==============================] - 0s - loss: 0.5614 - acc: 0.6938\nEpoch 411/500\n2400/2400 [==============================] - 0s - loss: 0.5554 - acc: 0.7154\nEpoch 412/500\n1800/2400 [=====================>........] - ETA: 0s - loss: 0.5552 - acc: 0.7132400/2400 [==============================] - 0s - loss: 0.5628 - acc: 0.7088\nEpoch 413/500\n2400/2400 [==============================] - 0s - loss: 0.5672 - acc: 0.7050\nEpoch 414/500\n2400/2400 [==============================] - 0s - loss: 0.5682 - acc: 0.6938\nEpoch 415/500\n2400/2400 [==============================] - 0s - loss: 0.5690 - acc: 0.6883\nEpoch 416/500\n2400/2400 [==============================] - 0s - loss: 0.5717 - acc: 0.6938\nEpoch 417/500\n2400/2400 [==============================] - 0s - loss: 0.5671 - acc: 0.6917\nEpoch 418/500\n2400/2400 [==============================] - 0s - loss: 0.5630 - acc: 0.6958\nEpoch 419/500\n2400/2400 [==============================] - 0s - loss: 0.5705 - acc: 0.7000\nEpoch 420/500\n2400/2400 [==============================] - 0s - loss: 0.5665 - acc: 0.6904\nEpoch 421/500\n2400/2400 [==============================] - 0s - loss: 0.5626 - acc: 0.7067\nEpoch 422/500\n2400/2400 [==============================] - 0s - loss: 0.5639 - acc: 0.7079\nEpoch 423/500\n2400/2400 [==============================] - 0s - loss: 0.5650 - acc: 0.7050\nEpoch 424/500\n2400/2400 [==============================] - 0s - loss: 0.5609 - acc: 0.7042\nEpoch 425/500\n2400/2400 [==============================] - 0s - loss: 0.5572 - acc: 0.7063\nEpoch 426/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6958\nEpoch 427/500\n2400/2400 [==============================] - 0s - loss: 0.5642 - acc: 0.6988\nEpoch 428/500\n2400/2400 [==============================] - 0s - loss: 0.5719 - acc: 0.6888\nEpoch 429/500\n2400/2400 [==============================] - 0s - loss: 0.5600 - acc: 0.7096\nEpoch 430/500\n2400/2400 [==============================] - 0s - loss: 0.5720 - acc: 0.6946\nEpoch 431/500\n2400/2400 [==============================] - 0s - loss: 0.5627 - acc: 0.6963\nEpoch 432/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.6988\nEpoch 433/500\n2400/2400 [==============================] - 0s - loss: 0.5654 - acc: 0.6971\nEpoch 434/500\n2400/2400 [==============================] - 0s - loss: 0.5674 - acc: 0.6938\nEpoch 435/500\n2400/2400 [==============================] - 0s - loss: 0.5733 - acc: 0.6879\nEpoch 436/500\n2400/2400 [==============================] - 0s - loss: 0.5675 - acc: 0.6979\nEpoch 437/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6979\nEpoch 438/500\n2400/2400 [==============================] - 0s - loss: 0.5647 - acc: 0.7042\nEpoch 439/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.6950\nEpoch 440/500\n2400/2400 [==============================] - 0s - loss: 0.5651 - acc: 0.7013\nEpoch 441/500\n2400/2400 [==============================] - 0s - loss: 0.5683 - acc: 0.6971\nEpoch 442/500\n2400/2400 [==============================] - 0s - loss: 0.5669 - acc: 0.6929\nEpoch 443/500\n2400/2400 [==============================] - 0s - loss: 0.5689 - acc: 0.6967\nEpoch 444/500\n2400/2400 [==============================] - 0s - loss: 0.5616 - acc: 0.6992\nEpoch 445/500\n2400/2400 [==============================] - 0s - loss: 0.5668 - acc: 0.6967\nEpoch 446/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6917\nEpoch 447/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.6917\nEpoch 448/500\n2400/2400 [==============================] - 0s - loss: 0.5650 - acc: 0.6979\nEpoch 449/500\n2400/2400 [==============================] - 0s - loss: 0.5680 - acc: 0.6946\nEpoch 450/500\n2400/2400 [==============================] - 0s - loss: 0.5583 - acc: 0.7025\nEpoch 451/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.7013\nEpoch 452/500\n2400/2400 [==============================] - 0s - loss: 0.5601 - acc: 0.7033\nEpoch 453/500\n2400/2400 [==============================] - 0s - loss: 0.5665 - acc: 0.6896\nEpoch 454/500\n2400/2400 [==============================] - 0s - loss: 0.5599 - acc: 0.7067\nEpoch 455/500\n2400/2400 [==============================] - 0s - loss: 0.5711 - acc: 0.6967\nEpoch 456/500\n2400/2400 [==============================] - 0s - loss: 0.5637 - acc: 0.6958\nEpoch 457/500\n2400/2400 [==============================] - 0s - loss: 0.5675 - acc: 0.6875\nEpoch 458/500\n2400/2400 [==============================] - 0s - loss: 0.5682 - acc: 0.6904\nEpoch 459/500\n2400/2400 [==============================] - 0s - loss: 0.5680 - acc: 0.6921\nEpoch 460/500\n2400/2400 [==============================] - 0s - loss: 0.5666 - acc: 0.6804\nEpoch 461/500\n2400/2400 [==============================] - 0s - loss: 0.5564 - acc: 0.7175\nEpoch 462/500\n2400/2400 [==============================] - 0s - loss: 0.5711 - acc: 0.6963\nEpoch 463/500\n2400/2400 [==============================] - 0s - loss: 0.5578 - acc: 0.7042\nEpoch 464/500\n2400/2400 [==============================] - 0s - loss: 0.5644 - acc: 0.7029\nEpoch 465/500\n2400/2400 [==============================] - 0s - loss: 0.5658 - acc: 0.6896\nEpoch 466/500\n2400/2400 [==============================] - 0s - loss: 0.5554 - acc: 0.7058\nEpoch 467/500\n2400/2400 [==============================] - 0s - loss: 0.5582 - acc: 0.7104\nEpoch 468/500\n2400/2400 [==============================] - 0s - loss: 0.5644 - acc: 0.7004\nEpoch 469/500\n2400/2400 [==============================] - 0s - loss: 0.5625 - acc: 0.6975\nEpoch 470/500\n2400/2400 [==============================] - 0s - loss: 0.5568 - acc: 0.7163\nEpoch 471/500\n2400/2400 [==============================] - 0s - loss: 0.5697 - acc: 0.6929\nEpoch 472/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.7021\nEpoch 473/500\n2400/2400 [==============================] - 0s - loss: 0.5595 - acc: 0.7038\nEpoch 474/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.7054\nEpoch 475/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.7017\nEpoch 476/500\n2400/2400 [==============================] - 0s - loss: 0.5629 - acc: 0.6933\nEpoch 477/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.6983\nEpoch 478/500\n2400/2400 [==============================] - 0s - loss: 0.5689 - acc: 0.6921\nEpoch 479/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.7054\nEpoch 480/500\n2400/2400 [==============================] - 0s - loss: 0.5641 - acc: 0.6983\nEpoch 481/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6950\nEpoch 482/500\n2400/2400 [==============================] - 0s - loss: 0.5638 - acc: 0.6975\nEpoch 483/500\n2400/2400 [==============================] - 0s - loss: 0.5616 - acc: 0.7013\nEpoch 484/500\n2400/2400 [==============================] - 0s - loss: 0.5583 - acc: 0.7117\nEpoch 485/500\n2400/2400 [==============================] - 0s - loss: 0.5704 - acc: 0.6925\nEpoch 486/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.7033\nEpoch 487/500\n2400/2400 [==============================] - 0s - loss: 0.5536 - acc: 0.7183\nEpoch 488/500\n2400/2400 [==============================] - 0s - loss: 0.5623 - acc: 0.6988\nEpoch 489/500\n2400/2400 [==============================] - 0s - loss: 0.5596 - acc: 0.7042\nEpoch 490/500\n2400/2400 [==============================] - 0s - loss: 0.5598 - acc: 0.6988\nEpoch 491/500\n2400/2400 [==============================] - 0s - loss: 0.5661 - acc: 0.6958\nEpoch 492/500\n2400/2400 [==============================] - 0s - loss: 0.5580 - acc: 0.7046\nEpoch 493/500\n2400/2400 [==============================] - 0s - loss: 0.5629 - acc: 0.6958\nEpoch 494/500\n2400/2400 [==============================] - 0s - loss: 0.5597 - acc: 0.7138\nEpoch 495/500\n2400/2400 [==============================] - 0s - loss: 0.5593 - acc: 0.7108\nEpoch 496/500\n2400/2400 [==============================] - 0s - loss: 0.5662 - acc: 0.6946\nEpoch 497/500\n2400/2400 [==============================] - 0s - loss: 0.5667 - acc: 0.6954\nEpoch 498/500\n2400/2400 [==============================] - 0s - loss: 0.5680 - acc: 0.6862\nEpoch 499/500\n2400/2400 [==============================] - 0s - loss: 0.5644 - acc: 0.7042\nEpoch 500/500\n2400/2400 [==============================] - 0s - loss: 0.5696 - acc: 0.6929\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x269edac6ef0>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "#__Fitting the ANN to the training set__\n",
    "classifier.fit(X_train, Y_train, batch_size=25, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___Part 3 Making the predictions and evaluating the model___\n",
    "\n",
    "#__Predicting the test set results__\n",
    "y_predicted_value = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_boolean = (y_predicted_value>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__making the error matrix also known as the confusion matrix__\n",
    "from sklearn.metrics import confusion_matrix\n",
    "error = confusion_matrix(Y_test,y_predicted_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.5933333333333334\n"
    }
   ],
   "source": [
    "accuracy_of_model = (299+57)/600\n",
    "print(accuracy_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python35064bitztdvenvvenvc8958502bcc84c59addbfddc77119dad",
   "display_name": "Python 3.5.0 64-bit ('ztd_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}