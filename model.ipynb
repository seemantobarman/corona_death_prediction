{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Data Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Importing the dataset__\n",
    "original_data = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__inserting random values in age__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"age\"]):\n",
    "        original_data.loc[_i, \"age\"] = random.randint(20,85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#__Spliting and removing replacing words__\n",
    "column_to_add = []\n",
    "for _symptom in original_data.loc[:,\"symptoms\"]:\n",
    "   if type(_symptom) == str:\n",
    "      _temp = _symptom.replace(\"feve\",\"fever\").replace(\"feaver\",\"fever\").replace(\"coughing\",\"cough\").replace(\"feverr\",\"fever\").replace(\"difficult in breathing\",\"difficulty breathing\")\n",
    "      column_to_add.extend(_temp.split(\",\"))\n",
    "#__individual symptoms__ \n",
    "new_column = []\n",
    "for _column in column_to_add:\n",
    "   _temp_clm = _column.strip()\n",
    "   new_column.append(_temp_clm)\n",
    "\n",
    "#__removing duplicates__\n",
    "new_column = list(dict.fromkeys(new_column))\n",
    "new_column = new_column[:20]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__adding the columns of symptoms in the main file__\n",
    "for _column in new_column:\n",
    "    original_data[_column] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Adding random items from the new_column in the Symptoms__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"symptoms\"]):\n",
    "        _random_int = random.randint(1,10)\n",
    "        original_data.at[_i, \"symptoms\"] = random.sample(new_column,k=_random_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the missing genders randomly__\n",
    "_gender = [\"male\",\"female\"]\n",
    "\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"gender\"]):\n",
    "        original_data.at[_i, \"gender\"] = random.choice(_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the missing death numbers randomly__\n",
    "for _i in range(len(original_data)):\n",
    "    if pd.isnull(original_data.loc[_i, \"death\"]):\n",
    "        original_data.at[_i, \"death\"] = random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Filling all the symptoms cells__\n",
    "original_data.iloc[:,5:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#__Selecting 1 if symptoms are detected__\n",
    "for _i in range(len(original_data)):\n",
    "    for _each in original_data.loc[_i, \"symptoms\"]:\n",
    "        original_data.at[_i,_each] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Final processed dataset__\n",
    "processed_data = original_data.drop(labels=\"symptoms\", axis=1).iloc[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Independent variable__\n",
    "X = processed_data.iloc[:,2:24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Dependent Variable (Death)__\n",
    "Y = processed_data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Encodeing the gender__\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "_labelEncoder_X_Gender = LabelEncoder()\n",
    "X[:,0] = _labelEncoder_X_Gender.fit_transform(X[:,0])\n",
    "\n",
    "_onehotencoder = OneHotEncoder(categorical_features= [0])\n",
    "X = _onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Avoiding dummy variable trap__\n",
    "\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Spliting the dataset into training set and test set__\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Feature Scaling__\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_parameters = sc.fit(X_train)\n",
    "\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = sc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Making the ANN__\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__initializing the ANN__\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Addind the input layer and the first hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu', input_dim=22))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the second hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the second hidden layer__\n",
    "classifier.add(Dense(output_dim=11, init='uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=.1))\n",
    "\n",
    "#__Adding the output layer__\n",
    "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "#__Compiling the ANN__\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "och 283/500\n2400/2400 [==============================] - 0s - loss: 0.5655 - acc: 0.6871\nEpoch 284/500\n2400/2400 [==============================] - 0s - loss: 0.5594 - acc: 0.6854\nEpoch 285/500\n2400/2400 [==============================] - 0s - loss: 0.5642 - acc: 0.6733\nEpoch 286/500\n2400/2400 [==============================] - 0s - loss: 0.5584 - acc: 0.6783\nEpoch 287/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6821\nEpoch 288/500\n2400/2400 [==============================] - 0s - loss: 0.5594 - acc: 0.6717\nEpoch 289/500\n2400/2400 [==============================] - 0s - loss: 0.5633 - acc: 0.6867\nEpoch 290/500\n2400/2400 [==============================] - 0s - loss: 0.5626 - acc: 0.6775\nEpoch 291/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.6838\nEpoch 292/500\n2400/2400 [==============================] - 0s - loss: 0.5582 - acc: 0.6750\nEpoch 293/500\n2400/2400 [==============================] - 0s - loss: 0.5592 - acc: 0.6804\nEpoch 294/500\n2400/2400 [==============================] - 0s - loss: 0.5697 - acc: 0.6725\nEpoch 295/500\n2400/2400 [==============================] - 0s - loss: 0.5582 - acc: 0.6838\nEpoch 296/500\n2400/2400 [==============================] - 0s - loss: 0.5627 - acc: 0.6750\nEpoch 297/500\n2400/2400 [==============================] - 0s - loss: 0.5635 - acc: 0.6638\nEpoch 298/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.6721\nEpoch 299/500\n2400/2400 [==============================] - 0s - loss: 0.5660 - acc: 0.6767\nEpoch 300/500\n2400/2400 [==============================] - 0s - loss: 0.5674 - acc: 0.6667\nEpoch 301/500\n2400/2400 [==============================] - 0s - loss: 0.5613 - acc: 0.6750\nEpoch 302/500\n2400/2400 [==============================] - 0s - loss: 0.5654 - acc: 0.6750\nEpoch 303/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6842\nEpoch 304/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6771\nEpoch 305/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6696\nEpoch 306/500\n2400/2400 [==============================] - 0s - loss: 0.5586 - acc: 0.6717\nEpoch 307/500\n2400/2400 [==============================] - 0s - loss: 0.5609 - acc: 0.6825\nEpoch 308/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6704\nEpoch 309/500\n2400/2400 [==============================] - 0s - loss: 0.5627 - acc: 0.6696\nEpoch 310/500\n2400/2400 [==============================] - 0s - loss: 0.5573 - acc: 0.6754\nEpoch 311/500\n2400/2400 [==============================] - 0s - loss: 0.5543 - acc: 0.6842\nEpoch 312/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6725\nEpoch 313/500\n2400/2400 [==============================] - 0s - loss: 0.5609 - acc: 0.6721\nEpoch 314/500\n2400/2400 [==============================] - 0s - loss: 0.5656 - acc: 0.6725\nEpoch 315/500\n2400/2400 [==============================] - 0s - loss: 0.5490 - acc: 0.6746\nEpoch 316/500\n2400/2400 [==============================] - 0s - loss: 0.5549 - acc: 0.6775\nEpoch 317/500\n2400/2400 [==============================] - 0s - loss: 0.5608 - acc: 0.6638\nEpoch 318/500\n2400/2400 [==============================] - 0s - loss: 0.5674 - acc: 0.6725\nEpoch 319/500\n2400/2400 [==============================] - 0s - loss: 0.5557 - acc: 0.6783\nEpoch 320/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6767\nEpoch 321/500\n2400/2400 [==============================] - 0s - loss: 0.5564 - acc: 0.6779\nEpoch 322/500\n2400/2400 [==============================] - 0s - loss: 0.5649 - acc: 0.6625\nEpoch 323/500\n2400/2400 [==============================] - 0s - loss: 0.5567 - acc: 0.6742\nEpoch 324/500\n2400/2400 [==============================] - 0s - loss: 0.5623 - acc: 0.6679\nEpoch 325/500\n2400/2400 [==============================] - 0s - loss: 0.5642 - acc: 0.6679\nEpoch 326/500\n2400/2400 [==============================] - 0s - loss: 0.5560 - acc: 0.6704\nEpoch 327/500\n2400/2400 [==============================] - 0s - loss: 0.5568 - acc: 0.6804\nEpoch 328/500\n2400/2400 [==============================] - 0s - loss: 0.5512 - acc: 0.6833\nEpoch 329/500\n2400/2400 [==============================] - 0s - loss: 0.5603 - acc: 0.6758\nEpoch 330/500\n2400/2400 [==============================] - 0s - loss: 0.5627 - acc: 0.6738\nEpoch 331/500\n2400/2400 [==============================] - 0s - loss: 0.5591 - acc: 0.6738\nEpoch 332/500\n2400/2400 [==============================] - 0s - loss: 0.5626 - acc: 0.6738\nEpoch 333/500\n2400/2400 [==============================] - 0s - loss: 0.5659 - acc: 0.6579\nEpoch 334/500\n2400/2400 [==============================] - 0s - loss: 0.5632 - acc: 0.6692\nEpoch 335/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6733\nEpoch 336/500\n2400/2400 [==============================] - 0s - loss: 0.5567 - acc: 0.6663\nEpoch 337/500\n2400/2400 [==============================] - 0s - loss: 0.5593 - acc: 0.6783\nEpoch 338/500\n2400/2400 [==============================] - 0s - loss: 0.5559 - acc: 0.6746\nEpoch 339/500\n2400/2400 [==============================] - 0s - loss: 0.5571 - acc: 0.6746\nEpoch 340/500\n2400/2400 [==============================] - 0s - loss: 0.5626 - acc: 0.6721\nEpoch 341/500\n2400/2400 [==============================] - 0s - loss: 0.5548 - acc: 0.6738\nEpoch 342/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6742\nEpoch 343/500\n2400/2400 [==============================] - 0s - loss: 0.5558 - acc: 0.6721\nEpoch 344/500\n2400/2400 [==============================] - 0s - loss: 0.5568 - acc: 0.6675\nEpoch 345/500\n2400/2400 [==============================] - 0s - loss: 0.5562 - acc: 0.6708\nEpoch 346/500\n2400/2400 [==============================] - 0s - loss: 0.5566 - acc: 0.6713\nEpoch 347/500\n2400/2400 [==============================] - 0s - loss: 0.5606 - acc: 0.6696\nEpoch 348/500\n2400/2400 [==============================] - 0s - loss: 0.5551 - acc: 0.6704\nEpoch 349/500\n2400/2400 [==============================] - 0s - loss: 0.5570 - acc: 0.6758\nEpoch 350/500\n2400/2400 [==============================] - 0s - loss: 0.5590 - acc: 0.6642\nEpoch 351/500\n2400/2400 [==============================] - 0s - loss: 0.5599 - acc: 0.6638\nEpoch 352/500\n2400/2400 [==============================] - 0s - loss: 0.5637 - acc: 0.6688\nEpoch 353/500\n2400/2400 [==============================] - 0s - loss: 0.5591 - acc: 0.6704\nEpoch 354/500\n2400/2400 [==============================] - 0s - loss: 0.5576 - acc: 0.6692\nEpoch 355/500\n2400/2400 [==============================] - 0s - loss: 0.5564 - acc: 0.6650\nEpoch 356/500\n2400/2400 [==============================] - 0s - loss: 0.5529 - acc: 0.6733\nEpoch 357/500\n2400/2400 [==============================] - 0s - loss: 0.5596 - acc: 0.6700\nEpoch 358/500\n2400/2400 [==============================] - 0s - loss: 0.5558 - acc: 0.6696\nEpoch 359/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6729\nEpoch 360/500\n2125/2400 [=========================>....] - ETA: 0s - loss: 0.5521 - acc: 0.6782400/2400 [==============================] - 0s - loss: 0.5549 - acc: 0.6779\nEpoch 361/500\n2400/2400 [==============================] - 0s - loss: 0.5586 - acc: 0.6658\nEpoch 362/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6750\nEpoch 363/500\n2400/2400 [==============================] - 0s - loss: 0.5612 - acc: 0.6658\nEpoch 364/500\n2400/2400 [==============================] - 0s - loss: 0.5533 - acc: 0.6725\nEpoch 365/500\n2400/2400 [==============================] - 0s - loss: 0.5618 - acc: 0.6608\nEpoch 366/500\n2400/2400 [==============================] - 0s - loss: 0.5562 - acc: 0.6692\nEpoch 367/500\n2400/2400 [==============================] - 0s - loss: 0.5551 - acc: 0.6625\nEpoch 368/500\n2400/2400 [==============================] - 0s - loss: 0.5562 - acc: 0.6717\nEpoch 369/500\n2400/2400 [==============================] - 0s - loss: 0.5618 - acc: 0.6633\nEpoch 370/500\n2400/2400 [==============================] - 0s - loss: 0.5528 - acc: 0.6604\nEpoch 371/500\n2400/2400 [==============================] - 0s - loss: 0.5606 - acc: 0.6558\nEpoch 372/500\n2400/2400 [==============================] - 0s - loss: 0.5604 - acc: 0.6667\nEpoch 373/500\n2400/2400 [==============================] - 0s - loss: 0.5594 - acc: 0.6733\nEpoch 374/500\n2400/2400 [==============================] - 0s - loss: 0.5515 - acc: 0.6604\nEpoch 375/500\n2400/2400 [==============================] - 0s - loss: 0.5595 - acc: 0.6663\nEpoch 376/500\n2400/2400 [==============================] - 0s - loss: 0.5628 - acc: 0.6633\nEpoch 377/500\n2400/2400 [==============================] - 0s - loss: 0.5530 - acc: 0.6671\nEpoch 378/500\n2400/2400 [==============================] - 0s - loss: 0.5483 - acc: 0.6633\nEpoch 379/500\n2400/2400 [==============================] - 0s - loss: 0.5646 - acc: 0.6667\nEpoch 380/500\n2400/2400 [==============================] - 0s - loss: 0.5572 - acc: 0.6625\nEpoch 381/500\n2400/2400 [==============================] - 0s - loss: 0.5560 - acc: 0.6621\nEpoch 382/500\n2400/2400 [==============================] - 0s - loss: 0.5584 - acc: 0.6533\nEpoch 383/500\n2400/2400 [==============================] - 0s - loss: 0.5597 - acc: 0.6713\nEpoch 384/500\n2400/2400 [==============================] - 0s - loss: 0.5535 - acc: 0.6729\nEpoch 385/500\n2400/2400 [==============================] - 0s - loss: 0.5468 - acc: 0.6792\nEpoch 386/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6679\nEpoch 387/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6658\nEpoch 388/500\n2400/2400 [==============================] - 0s - loss: 0.5598 - acc: 0.6671\nEpoch 389/500\n2400/2400 [==============================] - 0s - loss: 0.5583 - acc: 0.6667\nEpoch 390/500\n2400/2400 [==============================] - 0s - loss: 0.5544 - acc: 0.6738\nEpoch 391/500\n2400/2400 [==============================] - 0s - loss: 0.5615 - acc: 0.6588\nEpoch 392/500\n2400/2400 [==============================] - 0s - loss: 0.5592 - acc: 0.6646\nEpoch 393/500\n2400/2400 [==============================] - 0s - loss: 0.5548 - acc: 0.6725\nEpoch 394/500\n2400/2400 [==============================] - 0s - loss: 0.5611 - acc: 0.6638\nEpoch 395/500\n2400/2400 [==============================] - 0s - loss: 0.5567 - acc: 0.6558\nEpoch 396/500\n2400/2400 [==============================] - 0s - loss: 0.5552 - acc: 0.6767\nEpoch 397/500\n2400/2400 [==============================] - 0s - loss: 0.5550 - acc: 0.6708\nEpoch 398/500\n2400/2400 [==============================] - 0s - loss: 0.5636 - acc: 0.6638\nEpoch 399/500\n2400/2400 [==============================] - 0s - loss: 0.5579 - acc: 0.6617\nEpoch 400/500\n2400/2400 [==============================] - 0s - loss: 0.5500 - acc: 0.6713\nEpoch 401/500\n2400/2400 [==============================] - 0s - loss: 0.5628 - acc: 0.6704\nEpoch 402/500\n2400/2400 [==============================] - 0s - loss: 0.5499 - acc: 0.6688\nEpoch 403/500\n2400/2400 [==============================] - 0s - loss: 0.5610 - acc: 0.6667\nEpoch 404/500\n2400/2400 [==============================] - 0s - loss: 0.5483 - acc: 0.6713\nEpoch 405/500\n2400/2400 [==============================] - 0s - loss: 0.5589 - acc: 0.6704\nEpoch 406/500\n2400/2400 [==============================] - 0s - loss: 0.5627 - acc: 0.6600\nEpoch 407/500\n2400/2400 [==============================] - 0s - loss: 0.5588 - acc: 0.6671\nEpoch 408/500\n2400/2400 [==============================] - 0s - loss: 0.5573 - acc: 0.6704\nEpoch 409/500\n2400/2400 [==============================] - 0s - loss: 0.5588 - acc: 0.6683\nEpoch 410/500\n2400/2400 [==============================] - 0s - loss: 0.5593 - acc: 0.6633\nEpoch 411/500\n2400/2400 [==============================] - 0s - loss: 0.5600 - acc: 0.6675\nEpoch 412/500\n2400/2400 [==============================] - 0s - loss: 0.5534 - acc: 0.6721\nEpoch 413/500\n2400/2400 [==============================] - 0s - loss: 0.5686 - acc: 0.6567\nEpoch 414/500\n2400/2400 [==============================] - 0s - loss: 0.5591 - acc: 0.6617\nEpoch 415/500\n2400/2400 [==============================] - 0s - loss: 0.5593 - acc: 0.6671\nEpoch 416/500\n2400/2400 [==============================] - 0s - loss: 0.5572 - acc: 0.6671\nEpoch 417/500\n2400/2400 [==============================] - 0s - loss: 0.5603 - acc: 0.6604\nEpoch 418/500\n2400/2400 [==============================] - 0s - loss: 0.5546 - acc: 0.6671\nEpoch 419/500\n2400/2400 [==============================] - 0s - loss: 0.5624 - acc: 0.6671\nEpoch 420/500\n2400/2400 [==============================] - 0s - loss: 0.5578 - acc: 0.6671\nEpoch 421/500\n2400/2400 [==============================] - 0s - loss: 0.5586 - acc: 0.6671\nEpoch 422/500\n2400/2400 [==============================] - 0s - loss: 0.5465 - acc: 0.6638\nEpoch 423/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6633\nEpoch 424/500\n2400/2400 [==============================] - 0s - loss: 0.5585 - acc: 0.6663\nEpoch 425/500\n2400/2400 [==============================] - 0s - loss: 0.5510 - acc: 0.6579\nEpoch 426/500\n2400/2400 [==============================] - 0s - loss: 0.5602 - acc: 0.6504\nEpoch 427/500\n2400/2400 [==============================] - 0s - loss: 0.5543 - acc: 0.6671\nEpoch 428/500\n2400/2400 [==============================] - 0s - loss: 0.5613 - acc: 0.6654\nEpoch 429/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6671\nEpoch 430/500\n2400/2400 [==============================] - 0s - loss: 0.5588 - acc: 0.6671\nEpoch 431/500\n2400/2400 [==============================] - 0s - loss: 0.5503 - acc: 0.6671\nEpoch 432/500\n2400/2400 [==============================] - 0s - loss: 0.5524 - acc: 0.6650\nEpoch 433/500\n2400/2400 [==============================] - 0s - loss: 0.5535 - acc: 0.6671\nEpoch 434/500\n2400/2400 [==============================] - 0s - loss: 0.5528 - acc: 0.6583\nEpoch 435/500\n2400/2400 [==============================] - 0s - loss: 0.5547 - acc: 0.6579\nEpoch 436/500\n2400/2400 [==============================] - 0s - loss: 0.5477 - acc: 0.6646\nEpoch 437/500\n2400/2400 [==============================] - 0s - loss: 0.5601 - acc: 0.6625\nEpoch 438/500\n2400/2400 [==============================] - 0s - loss: 0.5579 - acc: 0.6650\nEpoch 439/500\n2400/2400 [==============================] - 0s - loss: 0.5564 - acc: 0.6671\nEpoch 440/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6671\nEpoch 441/500\n2400/2400 [==============================] - 0s - loss: 0.5549 - acc: 0.6671\nEpoch 442/500\n2400/2400 [==============================] - 0s - loss: 0.5519 - acc: 0.6617\nEpoch 443/500\n2400/2400 [==============================] - 0s - loss: 0.5592 - acc: 0.6704\nEpoch 444/500\n2400/2400 [==============================] - 0s - loss: 0.5569 - acc: 0.6633\nEpoch 445/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6671\nEpoch 446/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6671\nEpoch 447/500\n2400/2400 [==============================] - 0s - loss: 0.5528 - acc: 0.6650\nEpoch 448/500\n2400/2400 [==============================] - 0s - loss: 0.5540 - acc: 0.6563\nEpoch 449/500\n2400/2400 [==============================] - 0s - loss: 0.5546 - acc: 0.6600\nEpoch 450/500\n2400/2400 [==============================] - 0s - loss: 0.5566 - acc: 0.6754\nEpoch 451/500\n2400/2400 [==============================] - 0s - loss: 0.5556 - acc: 0.6621\nEpoch 452/500\n2400/2400 [==============================] - 0s - loss: 0.5479 - acc: 0.6583\nEpoch 453/500\n2400/2400 [==============================] - 0s - loss: 0.5522 - acc: 0.6638\nEpoch 454/500\n2400/2400 [==============================] - 0s - loss: 0.5510 - acc: 0.6650\nEpoch 455/500\n2400/2400 [==============================] - 0s - loss: 0.5554 - acc: 0.6575\nEpoch 456/500\n2400/2400 [==============================] - 0s - loss: 0.5519 - acc: 0.6621\nEpoch 457/500\n2400/2400 [==============================] - 0s - loss: 0.5512 - acc: 0.6708\nEpoch 458/500\n2400/2400 [==============================] - 0s - loss: 0.5580 - acc: 0.6663\nEpoch 459/500\n2400/2400 [==============================] - 0s - loss: 0.5572 - acc: 0.6638\nEpoch 460/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6567\nEpoch 461/500\n2400/2400 [==============================] - 0s - loss: 0.5514 - acc: 0.6592\nEpoch 462/500\n2400/2400 [==============================] - 0s - loss: 0.5549 - acc: 0.6646\nEpoch 463/500\n2400/2400 [==============================] - 0s - loss: 0.5580 - acc: 0.6671\nEpoch 464/500\n2400/2400 [==============================] - 0s - loss: 0.5596 - acc: 0.6671\nEpoch 465/500\n2400/2400 [==============================] - 0s - loss: 0.5466 - acc: 0.6671\nEpoch 466/500\n2400/2400 [==============================] - 0s - loss: 0.5536 - acc: 0.6638\nEpoch 467/500\n2400/2400 [==============================] - 0s - loss: 0.5588 - acc: 0.6671\nEpoch 468/500\n2400/2400 [==============================] - 0s - loss: 0.5501 - acc: 0.6675\nEpoch 469/500\n2400/2400 [==============================] - 0s - loss: 0.5545 - acc: 0.6675\nEpoch 470/500\n2400/2400 [==============================] - 0s - loss: 0.5652 - acc: 0.6642\nEpoch 471/500\n2400/2400 [==============================] - 0s - loss: 0.5371 - acc: 0.6671\nEpoch 472/500\n2400/2400 [==============================] - 0s - loss: 0.5535 - acc: 0.6654\nEpoch 473/500\n2400/2400 [==============================] - 0s - loss: 0.5505 - acc: 0.6646\nEpoch 474/500\n2400/2400 [==============================] - 0s - loss: 0.5521 - acc: 0.6654\nEpoch 475/500\n2400/2400 [==============================] - 0s - loss: 0.5568 - acc: 0.6617\nEpoch 476/500\n1675/2400 [===================>..........] - ETA: 0s - loss: 0.5369 - acc: 0.6612400/2400 [==============================] - 0s - loss: 0.5462 - acc: 0.6617\nEpoch 477/500\n2400/2400 [==============================] - 0s - loss: 0.5557 - acc: 0.6633\nEpoch 478/500\n2400/2400 [==============================] - 0s - loss: 0.5567 - acc: 0.6683\nEpoch 479/500\n2400/2400 [==============================] - 0s - loss: 0.5532 - acc: 0.6692\nEpoch 480/500\n2400/2400 [==============================] - 0s - loss: 0.5458 - acc: 0.6629\nEpoch 481/500\n2400/2400 [==============================] - 0s - loss: 0.5565 - acc: 0.6542\nEpoch 482/500\n2400/2400 [==============================] - 0s - loss: 0.5588 - acc: 0.6633\nEpoch 483/500\n2400/2400 [==============================] - 0s - loss: 0.5552 - acc: 0.6671\nEpoch 484/500\n2400/2400 [==============================] - 0s - loss: 0.5452 - acc: 0.6563\nEpoch 485/500\n2400/2400 [==============================] - 0s - loss: 0.5563 - acc: 0.6671\nEpoch 486/500\n2400/2400 [==============================] - 0s - loss: 0.5473 - acc: 0.6638\nEpoch 487/500\n2400/2400 [==============================] - 0s - loss: 0.5559 - acc: 0.6671\nEpoch 488/500\n2400/2400 [==============================] - 0s - loss: 0.5558 - acc: 0.6671\nEpoch 489/500\n2400/2400 [==============================] - 0s - loss: 0.5583 - acc: 0.6671\nEpoch 490/500\n2400/2400 [==============================] - 0s - loss: 0.5546 - acc: 0.6671\nEpoch 491/500\n2400/2400 [==============================] - 0s - loss: 0.5579 - acc: 0.6671\nEpoch 492/500\n2400/2400 [==============================] - 0s - loss: 0.5529 - acc: 0.6671\nEpoch 493/500\n2400/2400 [==============================] - 0s - loss: 0.5620 - acc: 0.6671\nEpoch 494/500\n2400/2400 [==============================] - 0s - loss: 0.5606 - acc: 0.6671\nEpoch 495/500\n2400/2400 [==============================] - 0s - loss: 0.5566 - acc: 0.6671\nEpoch 496/500\n2400/2400 [==============================] - 0s - loss: 0.5499 - acc: 0.6671\nEpoch 497/500\n2400/2400 [==============================] - 0s - loss: 0.5529 - acc: 0.6671\nEpoch 498/500\n2400/2400 [==============================] - 0s - loss: 0.5483 - acc: 0.6646\nEpoch 499/500\n2400/2400 [==============================] - 0s - loss: 0.5509 - acc: 0.6671\nEpoch 500/500\n2400/2400 [==============================] - 0s - loss: 0.5557 - acc: 0.6654\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16f1ffc32e8>"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "#__Fitting the ANN to the training set__\n",
    "classifier.fit(X_train, Y_train, batch_size=25, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___Part 3 Making the predictions and evaluating the model___\n",
    "\n",
    "#__Predicting the test set results__\n",
    "y_predicted_value = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_boolean = (y_predicted_value>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__making the error matrix also known as the confusion matrix__\n",
    "from sklearn.metrics import confusion_matrix\n",
    "error = confusion_matrix(Y_test,y_predicted_boolean)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python35064bitztdvenvvenvc8958502bcc84c59addbfddc77119dad",
   "display_name": "Python 3.5.0 64-bit ('ztd_venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}